{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ITMAL Exercise\r\n",
    "\r\n",
    "## Implementing a dummy binary-classifier with fit-predict interface\r\n",
    "\r\n",
    "We begin with the MNIST data-set and will reuse the data loader from Scikit-learn. Next we create a dummy classifier, and compare the results of the SGD and dummy classifiers using the MNIST data...\r\n",
    "\r\n",
    "#### Qa  Load and display the MNIST data\r\n",
    "\r\n",
    "There is a `sklearn.datasets.fetch_openml` dataloader interface in Scikit-learn. You can load MNIST data like \r\n",
    "\r\n",
    "```python\r\n",
    "from sklearn.datasets import fetch_openml\r\n",
    "# Load data from https://www.openml.org/d/554\r\n",
    "X, y = fetch_openml('mnist_784',??) # needs to return X, y, replace '??' with suitable parameters! \r\n",
    "# Convert to [0;1] via scaling (not always needed)\r\n",
    "#X = X / 255.\r\n",
    "```\r\n",
    "\r\n",
    "but you need to set parameters like `return_X_y` and `cache` if the default values are not suitable! \r\n",
    "\r\n",
    "Check out the documentation for the `fetch_openml` MNIST loader, try it out by loading a (X,y) MNIST data set, and plot a single digit via the `MNIST_PlotDigit` function here (input data is a 28x28 NMIST subimage)\r\n",
    "\r\n",
    "```python\r\n",
    "%matplotlib inline\r\n",
    "def MNIST_PlotDigit(data):\r\n",
    "    import matplotlib\r\n",
    "    import matplotlib.pyplot as plt\r\n",
    "    image = data.reshape(28, 28)\r\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\r\n",
    "    plt.axis(\"off\")\r\n",
    "```\r\n",
    "\r\n",
    "Finally, put the MNIST loader into a single function called `MNIST_GetDataSet()` so you can resuse it later."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# TODO: add your code here..\r\n",
    "from sklearn.datasets import fetch_openml\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "import matplotlib\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "def MNIST_GetDataSet():\r\n",
    "    X, y = fetch_openml('mnist_784', cache=True, return_X_y=True, as_frame=False)\r\n",
    "    #X= X.reshape(70000, 28, 28)\r\n",
    "    # X_std = (X-X.min(axis=0))/(X.max(axis=0)- X.min(axis=0))\r\n",
    "    # X = X_std *(max-min)+min\r\n",
    "    # X = X/255\r\n",
    "    return X, y\r\n",
    "\r\n",
    "X, y = MNIST_GetDataSet()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import matplotlib\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "def MNIST_PlotDigit(data):\r\n",
    "    image = data.reshape(28,28)\r\n",
    "    plt.imshow(image, cmap=matplotlib.cm.binary, interpolation=\"nearest\")\r\n",
    "    plt.axis(\"off\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Qb  Add a Stochastic Gradient Decent [SGD] Classifier\n",
    "\n",
    "Create a train-test data-set for MNIST and then add the `SGDClassifier` as done in [HOML], p.88.\n",
    "\n",
    "Split your data and run the fit-predict for the classifier using the MNIST data.(We will be looking at cross-validation instead of the simple fit-predict in a later exercise.)\n",
    "\n",
    "Notice that you have to reshape the MNIST X-data to be able to use the classifier. It may be a 3D array, consisting of 70000 (28 x 28) images, or just a 2D array consisting of 70000 elements of size 784.\n",
    "\n",
    "A simple `reshape()` could fix this on-the-fly:\n",
    "```python\n",
    "X, y = MNIST_GetDataSet()\n",
    "\n",
    "print(f\"X.shape={X.shape}\") # print X.shape= (70000, 28, 28)\n",
    "if X.ndim==3:\n",
    "    print(\"reshaping X..\")\n",
    "    assert y.ndim==1\n",
    "    X = X.reshape((X.shape[0],X.shape[1]*X.shape[2]))\n",
    "assert X.ndim==2\n",
    "print(f\"X.shape={X.shape}\") # X.shape= (70000, 784)\n",
    "```\n",
    "\n",
    "Remember to use the category-5 y inputs\n",
    "\n",
    "```python\n",
    "y_train_5 = (y_train == '5')    \n",
    "y_test_5  = (y_test == '5')\n",
    "```\n",
    "instead of the `y`'s you are getting out of the dataloader. In effect, we have now created a binary-classifier, that enable us to classify a particular data sample, $\\mathbf{x}(i)$ (that is a 28x28 image), as being a-class-5 or not-a-class-5. \n",
    "\n",
    "Test your model on using the test data, and try to plot numbers that have been categorized correctly. Then also find and plots some misclassified numbers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# TODO: add your code here..\r\n",
    "from sklearn.linear_model import SGDClassifier\r\n",
    "#X, y = MNIST_GetDataSet()\r\n",
    "\r\n",
    "print(f\"X.shape={X.shape}\")\r\n",
    "print(f\"y.shape={y.shape}\")\r\n",
    "\r\n",
    "MNIST_PlotDigit(X[0])\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\r\n",
    "y_train_5 = (y_train==\"5\")\r\n",
    "y_test_5 = (y_test==\"5\")\r\n",
    "sgd_clf = SGDClassifier(random_state=42)\r\n",
    "sgd_clf.fit(X_train, y_train_5)\r\n",
    "\r\n",
    "#MNIST_PlotDigit(X[0])\r\n",
    "#MNIST_PlotDigit(X[1])\r\n",
    "#MNIST_PlotDigit(X[2])\r\n",
    "MNIST_PlotDigit(X_test[8])\r\n",
    "#print(f\"y_test[1]={y_test[1]}\")\r\n",
    "#print(f\"y_test[2]={y_test[2]}\")\r\n",
    "print(f\"y[8]={y_test[8]}\")\r\n",
    "#sgd_clf.predict([X_test[0]])\r\n",
    "#sgd_clf.predict([X_test[1]])\r\n",
    "#sgd_clf.predict([X_test[2]])\r\n",
    "sgd_clf.predict([X_test[8]])\r\n",
    "#assert False, \"TODO: solve Qb, and remove me..\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X.shape=(70000, 784)\n",
      "y.shape=(70000,)\n",
      "y[8]=5\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Qc Implement a dummy binary classifier\r\n",
    "\r\n",
    "Now we will try to create a Scikit-learn compatible estimator implemented via a python class. Follow the code found in [HOML], p.90, but name you estimator `DummyClassifier` instead of `Never5Classifyer`.\r\n",
    "\r\n",
    "Here our Python class knowledge comes into play. The estimator class hierarchy looks like\r\n",
    "\r\n",
    "<img src=\"https://itundervisning.ase.au.dk/GITMAL/L02/Figs/class_base_estimator.png\" alt=\"WARNING: you need to be logged into Blackboard to view images\" style=\"width:500px\">\r\n",
    "\r\n",
    "All Scikit-learn classifiers inherit from `BaseEstimator` (and possibly also `ClassifierMixin`), and they must have a `fit-predict` function pair (strangely not in the base class!) and you can actually find the `sklearn.base.BaseEstimator` and `sklearn.base.ClassifierMixin` python source code somewhere in you anaconda install dir, if you should have the nerves to go to such interesting details.\r\n",
    "\r\n",
    "But surprisingly you may just want to implement a class that contains the `fit-predict` functions, ___without inheriting___ from the `BaseEstimator`, things still work due to the pythonic 'duck-typing': you just need to have the class implement the needed interfaces, obviously `fit()` and `predict()` but also the more obscure `get_params()` etc....then the class 'looks like' a `BaseEstimator`...and if it looks like an estimator, it _is_ an estimator (aka. duck typing).\r\n",
    "\r\n",
    "Templates in C++ also allow the language to use compile-time duck typing!\r\n",
    "\r\n",
    "> https://en.wikipedia.org/wiki/Duck_typing\r\n",
    "\r\n",
    "Call the fit-predict on a newly instantiated `DummyClassifier` object, and find a way to extract the accuracy `score` from the test data. You may implement an accuracy function yourself or just use the `sklearn.metrics.accuracy_score` function. \r\n",
    "\r\n",
    "Finally, compare the accuracy score from your `DummyClassifier` with the scores found in [HOML] \"Measuring Accuracy Using Cross-Validation\", p.89. Are they comparable? "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# TODO: add your code here..\r\n",
    "from sklearn.base import BaseEstimator\r\n",
    "from sklearn.base import ClassifierMixin\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "import numpy as np\r\n",
    "class DummyClassifier(BaseEstimator, ClassifierMixin):\r\n",
    "    def fit(self, X, y=None):\r\n",
    "        pass\r\n",
    "    def predict(self, X):\r\n",
    "        return np.zeros((len(X), 1), dtype=bool)\r\n",
    "\r\n",
    "dummy_5_clf = DummyClassifier()\r\n",
    "\r\n",
    "cross_val_score(dummy_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\r\n",
    "\r\n",
    "\r\n",
    "#Compare scores from \"Measuring Accuracy Using Cross-Validation\":\r\n",
    "#array([0.96355, 0.93795, 0.95615])\r\n",
    "#Predict never 5: array([0.91125, 0.90855, 0.90915])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n",
      "[False]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.90965, 0.90965, 0.90965])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Qd Conclusion\n",
    "\n",
    "Now, conclude on all the exercise above. \n",
    "\n",
    "Write a short textual conclusion (max. 10- to 20-lines) that extract the _essence_ of the exercises: why did you think it was important to look at these particular ML concepts, and what was our overall learning outcome of the exercises (in broad terms)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: Qd concluding remarks in text.."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "REVISIONS||\n",
    "---------||\n",
    "2018-12-19| CEF, initial.                  \n",
    "2018-02-06| CEF, updated and spell checked. \n",
    "2018-02-08| CEF, minor text update.\n",
    "2018-03-05| CEF, updated with SHN comments.\n",
    "2019-09-02| CEF, updated for ITMAL v2.\n",
    "2019-09-04| CEF, updated and added conclusion Q.\n",
    "2020-01-25| CEF, F20 ITMAL update.\n",
    "2020-02-04| CEF, updated page numbers to HOMLv2.\n",
    "2020-09-03| CEF, E20 ITMAL update, udpated figs paths.\n",
    "2020-09-06| CEF, added alt text.\n",
    "2020-09-18| CEF, added binary-classifier text to Qb to emphasise 5/non-5 classification.\n",
    "2021-01-12| CEF, F21 ITMAL update, moved revision tabel.\n",
    "2021-08-02| CEF, update to E21 ITMAL."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.517px",
    "left": "1230px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  },
  "interpreter": {
   "hash": "8ac103a4ea7a9ce6b38a3bae78d3f7aa3ec13c6a5fd842cb0d2c99a5dc8b8544"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}